{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f8443440",
      "metadata": {},
      "source": [
        "# Base Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3110c90f",
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://github.com/Edouard99/GAN.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d65118bc-fa51-4dc9-b2ed-fb311a0ffd00",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d65118bc-fa51-4dc9-b2ed-fb311a0ffd00",
        "outputId": "f4fe4cf3-47f4-4ca7-957f-1775e2d54830"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn\n",
        "import torch.backends.cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import matplotlib.animation as animation\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "from IPython.display import clear_output\n",
        "from IPython.display import HTML\n",
        "import random\n",
        "from PIL import Image\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a35d463",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"This cell import the dataset and according to the image type and size\n",
        "For now the designed GAN are for 64px and 256px images\n",
        "Available dataset are Pokemon 64px and 256px\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "image_type=\"pokemon\" # Only type of data available for now\n",
        "image_size=64 # Choose between 64 and 256\n",
        "\n",
        "\n",
        "os.mkdir(\"/content/data\")\n",
        "os.mkdir(\"/content/data/img_ds\")\n",
        "os.mkdir(\"/content/results\")\n",
        "os.mkdir(\"/content/net\")\n",
        "\n",
        "if image_type==\"pokemon\":\n",
        "    if image_size==64:\n",
        "        !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1mKWPRvdYg6jfN6G8AFxsHpzjo3608QaJ' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1mKWPRvdYg6jfN6G8AFxsHpzjo3608QaJ\" -O /content/poke_ds_64.zip && rm -rf /tmp/cookies.txt\n",
        "        !unzip -q /content/poke_ds_64.zip -d /content/data/img_ds\n",
        "        !rm /content/poke_ds_64.zip\n",
        "    if image_size==256:\n",
        "        !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=19sQKN9H4gmNPxQLLtjDmw5SV5KZ4Q1n1' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=19sQKN9H4gmNPxQLLtjDmw5SV5KZ4Q1n1\" -O /content/poke_ds_256.zip && rm -rf /tmp/cookies.txt\n",
        "        !unzip -q /content/poke_ds_256.zip -d /content/data/img_ds\n",
        "        !rm /content/poke_ds_256.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce27147c",
      "metadata": {},
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a255ff13-51d3-4f4a-8378-38947b591031",
      "metadata": {
        "id": "a255ff13-51d3-4f4a-8378-38947b591031"
      },
      "outputs": [],
      "source": [
        "dataroot = \"/content/data/img_ds\" # Image Dataset path\n",
        "\n",
        "workers = 2 # Number of workers for dataloader\n",
        "\n",
        "batch_size = 32 # Batch Size\n",
        "\n",
        "nc = 3 # Number of channels in the training images. For color images this is 3\n",
        "\n",
        "nz = 16 # Size of latente space (input vector of generator)\n",
        "\n",
        "ngf = 128 # Number of filter used in the generator (see doc)\n",
        "\n",
        "ndf = 128 # Number of filter used in the discriminant (see doc)\n",
        "\n",
        "ngpu = 1 # Is GPU available ? use 1 for GPU and 0 for CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2740631c",
      "metadata": {},
      "source": [
        "# Dataset Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "860bc415",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" This cell ensures reproducibility of the results, I used the seed 666 in my project, feel free to change the seed for new results \"\"\"\n",
        "\n",
        "manualSeed = 666\n",
        "\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "np.random.seed(manualSeed)\n",
        "torch.cuda.manual_seed_all(manualSeed)\n",
        "torch.cuda.manual_seed(manualSeed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.use_deterministic_algorithms(True)\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":4096:8\"\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "\n",
        "g = torch.Generator()\n",
        "g.manual_seed(manualSeed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5d2c4e2-f889-41b2-8286-2064470c5cbb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "c5d2c4e2-f889-41b2-8286-2064470c5cbb",
        "outputId": "4fc75c0a-1aa5-4749-d090-f66176ec9568"
      },
      "outputs": [],
      "source": [
        "\"\"\" This cell creates the dataloader that will provide the images to the neural network, images are centered, resized (if necessary) and normalized\"\"\"\n",
        "\n",
        "dataset = dset.ImageFolder(root=dataroot,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                           ]))\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                         shuffle=True, num_workers=workers,pin_memory=True,worker_init_fn=seed_worker,generator=g)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\") # GPU or CPU\n",
        "\n",
        "# Plot some training images\n",
        "real_batch = next(iter(dataloader))\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6a37ec4",
      "metadata": {},
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cac616a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" This cell allows to select the model and the training type used\"\"\"\n",
        "gan_mode=\"dcgan\" #Gan Type, choose between \"dcgan\" and \"wgan\"\n",
        "training_mode=\"boosting\" #Training mode, choose between {\"classic\", \"monitoring\", \"boosting\"} for DCGAN and {\"wgan\"} for Wgan\n",
        "\n",
        "# Learning rate for optimizers:\n",
        "lr_dcgan = 0.00015\n",
        "lr_wgan= 5e-5\n",
        "# Beta1 hyperparam for Adam optimizers (dcgan)\n",
        "beta1 = 0.5\n",
        "\n",
        "\n",
        "# Select and import the model and trainer regarding what you selected for gan_mode and training_mode\n",
        "if gan_mode==\"wgan\":\n",
        "  training_mode=gan_mode\n",
        "else:\n",
        "  if training_mode==\"wgan\":\n",
        "    training_mode=\"classic\"\n",
        "if image_size==64:\n",
        "    from GAN.Models import gan64 as model\n",
        "elif image_size==256:\n",
        "    from GAN.Models import gan256 as model\n",
        "\n",
        "if training_mode==\"classic\":\n",
        "    from GAN.Trainings import training_classic as trainer\n",
        "if training_mode==\"boosting\":\n",
        "    from GAN.Trainings import training_boosting as trainer\n",
        "if training_mode==\"monitoring\":\n",
        "    from GAN.Trainings import training_monitoring as trainer\n",
        "if gan_mode==\"wgan\":\n",
        "    from GAN.Trainings import training_wgan as trainer\n",
        "\n",
        "\n",
        "# Create the generator\n",
        "netG = model.Generator(nz,ngf,nc).to(device)\n",
        "netG.apply(model.weights_init)\n",
        "\n",
        "# Create the Discriminator\n",
        "netD = model.Discriminator(nc,ndf,device,mode=gan_mode).to(device)\n",
        "netD.apply(model.weights_init)\n",
        "\n",
        "fixed_noise = torch.randn(64, nz, 1, 1, device=device) # This is a fixed noise that will be used to generate a grid of images saved evey 4 epochs\n",
        "\n",
        "#Create the optimizers\n",
        "if gan_mode==\"dcgan\":\n",
        "    optimizerD = optim.Adam(netD.parameters(), lr=lr_dcgan, betas=(beta1, 0.999))\n",
        "    optimizerG = optim.Adam(netG.parameters(), lr=lr_dcgan, betas=(beta1, 0.999))\n",
        "if gan_mode==\"wgan\":\n",
        "    optimizerD = optim.RMSprop(netD.parameters(), lr=lr_wgan)\n",
        "    optimizerG = optim.RMSprop(netG.parameters(), lr=lr_wgan)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6303d6f",
      "metadata": {},
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "85105daa-bb3a-4aa2-8cd6-4c1b8d43f647",
      "metadata": {
        "id": "85105daa-bb3a-4aa2-8cd6-4c1b8d43f647"
      },
      "outputs": [],
      "source": [
        "\"\"\" This cell trains the networks \n",
        "    During the training, the network's weights are saved(can be disabled) and a grid of images(based on fixed_noise) is generated and saved at each epoch\n",
        "\n",
        "Please use train function as:\n",
        "    train(dataloader,discriminant_net,generator_net,discriminant_optimizer,generator_optimizer,number_of_epochs,\n",
        "                device(CPU/GPU),save_the_net_parameters(True/False),net_saving_path,image_grid_saving_path,fixed_noise)\n",
        "\n",
        "For monitored training there is 2 more parameters that can be set by the user, please refer to training_monitoring.py\n",
        "\"\"\"\n",
        "\n",
        "img_list,G_losses,D_losses=trainer.train(dataloader,netD,netG,optimizerD,optimizerG,150,device,True,\"/content/net/\",\"/content/results/\",fixed_noise)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cd112e7-4443-4005-b5d7-3a2b5d1356e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1cd112e7-4443-4005-b5d7-3a2b5d1356e5",
        "outputId": "6d13a4b0-5c1d-4890-8ee0-7ece303b8608"
      },
      "outputs": [],
      "source": [
        "\"\"\"Generate an animation of all the image grid saved during training\"\"\"\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list[0:len(img_list)]]\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
        "\n",
        "HTML(ani.to_jshtml())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "k9YUa05J0toP"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "acb408c112aa627a318ac6bee697c54a21dc0d988d17c05deacc60f98e48531a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
